{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1THVzPVqCVUnI3LAZlKCDUTf29S_76B46",
      "authorship_tag": "ABX9TyMaSMX2CZnBmNnJB2or+t/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helya02/HomeWorks/blob/main/06_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/NN06/geometry_dataset.zip'\n",
        "target_dir = os.path.dirname(zip_path)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target_dir)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LibA0LOaIrAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/geometry_dataset.zip"
      ],
      "metadata": {
        "id": "LlvxkjIkKjRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#params\n",
        "DATASET_DIR = \"/content/output\"\n",
        "TRAIN_IMAGES_PER_CLASS = 8000\n",
        "TEST_IMAGES_PER_CLASS = 2000\n",
        "NUM_CLASSES = 9\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "MODEL_SAVE_PATH = \"/content/0602-22401349-HashemiAghdam.pt\"\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"L\")\n",
        "    transform = transforms.ToTensor()\n",
        "    return transform(image)\n",
        "\n",
        "class GeometryDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"L\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def prepare_data():\n",
        "\n",
        "    class_files = {}\n",
        "    file_pattern = os.path.join(DATASET_DIR, \"*.png\")\n",
        "    for file in glob.glob(file_pattern):\n",
        "        basename = os.path.basename(file)\n",
        "        for label in [\"Circle\", \"Hexagon\", \"Heptagon\", \"Nonagon\", \"Octagon\", \"Pentagon\", \"Square\", \"Star\", \"Triangle\"]:\n",
        "            if basename.startswith(label):\n",
        "                class_files.setdefault(label, []).append(file)\n",
        "                break\n",
        "\n",
        "    train_files, test_files = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "\n",
        "\n",
        "    for label in sorted(class_files.keys()):\n",
        "        files = sorted(class_files[label])\n",
        "        if len(files) < (TRAIN_IMAGES_PER_CLASS + TEST_IMAGES_PER_CLASS):\n",
        "            print(f\"Warning: Not enough images for class {label}. Found {len(files)} images.\")\n",
        "            continue\n",
        "        train_list = files[:TRAIN_IMAGES_PER_CLASS]\n",
        "        test_list = files[TRAIN_IMAGES_PER_CLASS:TRAIN_IMAGES_PER_CLASS + TEST_IMAGES_PER_CLASS]\n",
        "        train_files.extend(train_list)\n",
        "        test_files.extend(test_list)\n",
        "        train_labels.extend([label] * len(train_list))\n",
        "        test_labels.extend([label] * len(test_list))\n",
        "\n",
        "\n",
        "    with open(\"/content/training.file\", \"wb\") as f:\n",
        "        pickle.dump((train_files, train_labels), f)\n",
        "    with open(\"/content/testing.file\", \"wb\") as f:\n",
        "        pickle.dump((test_files, test_labels), f)\n",
        "\n",
        "    return (train_files, train_labels), (test_files, test_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "edgtcJh8GaVs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# class SimpleCNN(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(SimpleCNN, self).__init__()\n",
        "#         # Input channel = 1 for grayscale images; change to 3 for RGB images.\n",
        "#         self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\n",
        "#         # Assuming two poolings: from 200x200 to 50x50 feature maps.\n",
        "#         self.fc1 = nn.Linear(64 * 50 * 50, 256)\n",
        "#         self.fc2 = nn.Linear(256, NUM_CLASSES)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.conv1(x))\n",
        "#         x = self.pool(x)  # Reduces size from 200 to 100\n",
        "#         x = F.relu(self.conv2(x))\n",
        "#         x = self.pool(x)  # Reduces size from 100 to 50\n",
        "#         x = x.view(x.size(0), -1)  # Flatten\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n",
        "# class ImprovedCNN(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(ImprovedCNN, self).__init__()\n",
        "#         self.features = nn.Sequential(\n",
        "#             nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "\n",
        "#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "\n",
        "#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "\n",
        "#             nn.Dropout(0.3)\n",
        "#         )\n",
        "\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Linear(128 * 25 * 25, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(512, NUM_CLASSES)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n",
        "\n",
        "class EfficientCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EfficientCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 200 -> 100\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 100 -> 50\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 50 -> 25\n",
        "\n",
        "            nn.Dropout(0.3),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))  # Output: 128 x 1 x 1\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),  # from (128, 1, 1) to (128)\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, device):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    label_to_index = {\"Circle\":0, \"Hexagon\":1, \"Heptagon\":2, \"Nonagon\":3,\n",
        "                      \"Octagon\":4, \"Pentagon\":5, \"Square\":6, \"Star\":7, \"Triangle\":8}\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            targets = torch.tensor([label_to_index[label] for label in labels]).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += targets.size(0)\n",
        "            correct_train += (predicted == targets).sum().item()\n",
        "\n",
        "        epoch_loss_train = running_loss / total_train\n",
        "        epoch_acc_train = correct_train / total_train\n",
        "        train_losses.append(epoch_loss_train)\n",
        "        train_accuracies.append(epoch_acc_train)\n",
        "\n",
        "        model.eval()\n",
        "        running_loss_test = 0.0\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images = images.to(device)\n",
        "                targets = torch.tensor([label_to_index[label] for label in labels]).to(device)\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                running_loss_test += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_test += targets.size(0)\n",
        "                correct_test += (predicted == targets).sum().item()\n",
        "\n",
        "        epoch_loss_test = running_loss_test / total_test\n",
        "        epoch_acc_test = correct_test / total_test\n",
        "        test_losses.append(epoch_loss_test)\n",
        "        test_accuracies.append(epoch_acc_test)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{num_epochs}  Train Loss: {epoch_loss_train:.4f}  Train Acc: {epoch_acc_train:.4f}  Test Loss: {epoch_loss_test:.4f}  Test Acc: {epoch_acc_test:.4f}\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, num_epochs+1), train_losses, label=\"Train Loss\")\n",
        "    plt.plot(range(1, num_epochs+1), test_losses, label=\"Test Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Epoch vs Loss\")\n",
        "    plt.savefig(\"loss_plot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, num_epochs+1), train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(range(1, num_epochs+1), test_accuracies, label=\"Test Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Epoch vs Accuracy\")\n",
        "    plt.savefig(\"accuracy_plot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    return model, train_losses, test_losses, train_accuracies, test_accuracies"
      ],
      "metadata": {
        "id": "KFeiXVwXFIwS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Main\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    with open(\"/content/training.file\", \"rb\") as f:\n",
        "      train_files, train_labels = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/testing.file\", \"rb\") as f:\n",
        "      test_files, test_labels = pickle.load(f)\n",
        "\n",
        "    # Data transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomResizedCrop(200, scale=(0.9, 1.0)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    test_transform = transforms.ToTensor()\n",
        "\n",
        "    # Datasets and loaders\n",
        "    train_dataset = GeometryDataset(train_files, train_labels, transform=train_transform)\n",
        "    test_dataset = GeometryDataset(test_files, test_labels, transform=test_transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "    model = EfficientCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    model, train_losses, test_losses, train_accuracies, test_accuracies = train_model(model, train_loader, test_loader, criterion, optimizer, NUM_EPOCHS, device)\n",
        "\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
        "\n",
        "    metrics = {\n",
        "        \"train_losses\": train_losses,\n",
        "        \"test_losses\": test_losses,\n",
        "        \"train_accuracies\": train_accuracies,\n",
        "        \"test_accuracies\": test_accuracies\n",
        "    }\n",
        "    with open(\"training_metrics.pkl\", \"wb\") as f:\n",
        "        pickle.dump(metrics, f)"
      ],
      "metadata": {
        "id": "1o86sKW5FO88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f206c4-4763-4271-a89f-582dd48fb44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-10-caf0755bee6f>:100: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-10-caf0755bee6f>:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crHZstABNfy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5SD_932fNfuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# -------------------------------\n",
        "# Define the same CNN model structure for inference\n",
        "# -------------------------------\n",
        "NUM_CLASSES = 9\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 50 * 50, 256)\n",
        "        self.fc2 = nn.Linear(256, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# -------------------------------\n",
        "# Label mapping: index to class label\n",
        "# -------------------------------\n",
        "index_to_label = {0:\"Circle\", 1:\"Hexagon\", 2:\"Heptagon\", 3:\"Nonagon\",\n",
        "                  4:\"Octagon\", 5:\"Pentagon\", 6:\"Square\", 7:\"Star\", 8:\"Triangle\"}\n",
        "\n",
        "# -------------------------------\n",
        "# Load and preprocess an image\n",
        "# -------------------------------\n",
        "def load_and_preprocess(image_path):\n",
        "    image = Image.open(image_path).convert(\"L\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((200, 200)),  # Resize image to 200x200 pixels\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image_tensor = transform(image)\n",
        "    # Add batch dimension\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    return image_tensor\n",
        "\n",
        "# -------------------------------\n",
        "# Main inference function\n",
        "# -------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_SAVE_PATH = \"/content/0602-IDNumber-LastName.pt\"  # Make sure the path matches the saved model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Initialize model and load state\n",
        "    model = SimpleCNN().to(device)\n",
        "    model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    # Process all images in the current directory (modify the pattern as needed)\n",
        "    image_files = [f for f in os.listdir(\".\") if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "    results = {}\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_tensor = load_and_preprocess(image_file)\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(image_tensor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predicted_label = index_to_label[int(predicted)]\n",
        "        results[image_file] = predicted_label\n",
        "\n",
        "    # Print inference results as required\n",
        "    for img, label in results.items():\n",
        "        print(f\"{img}: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp8392ChNlsd",
        "outputId": "a23847af-a9c1-4ab7-ba06-2255d6efc597",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Circle_ea2f9192-2a97-11ea-8123-8363a7ec19e6.png: Circle\n",
            "Square_eb0e858c-2a97-11ea-8123-8363a7ec19e6.png: Triangle\n",
            "Triangle_b3dd0a70-2a97-11ea-8123-8363a7ec19e6.png: Triangle\n",
            "Hexagon_c93b3c84-2a97-11ea-8123-8363a7ec19e6.png: Hexagon\n",
            "Circle_e429c7a4-2a97-11ea-8123-8363a7ec19e6.png: Octagon\n",
            "Heptagon_c4df22fe-2a97-11ea-8123-8363a7ec19e6.png: Heptagon\n",
            "Hexagon_bdc7a662-2a97-11ea-8123-8363a7ec19e6.png: Hexagon\n",
            "Hexagon_b1b6f594-2a97-11ea-8123-8363a7ec19e6.png: Hexagon\n",
            "Triangle_e9840cdc-2a97-11ea-8123-8363a7ec19e6.png: Triangle\n",
            "Pentagon_a98e9318-2a97-11ea-8123-8363a7ec19e6.png: Pentagon\n",
            "Octagon_b714bb2a-2a97-11ea-8123-8363a7ec19e6.png: Octagon\n",
            "Nonagon_d9b6ce2a-2a97-11ea-8123-8363a7ec19e6.png: Octagon\n",
            "Triangle_cbfc5714-2a97-11ea-8123-8363a7ec19e6.png: Square\n",
            "Square_c0db9e80-2a97-11ea-8123-8363a7ec19e6.png: Triangle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inferences"
      ],
      "metadata": {
        "id": "ZGvIVzxrMk7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "NUM_CLASSES = 9\n",
        "\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 25 * 25, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "index_to_label = {\n",
        "    0: \"Circle\", 1: \"Hexagon\", 2: \"Heptagon\", 3: \"Nonagon\",\n",
        "    4: \"Octagon\", 5: \"Pentagon\", 6: \"Square\", 7: \"Star\", 8: \"Triangle\"\n",
        "}\n",
        "\n",
        "\n",
        "def load_and_preprocess(image_path):\n",
        "    image = Image.open(image_path).convert(\"L\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((200, 200)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    return image_tensor\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_PATH = \"/content/0602-22401349-HashemiAghdam.pt\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ImprovedCNN().to(device)\n",
        "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    image_files = [f for f in os.listdir(\".\") if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "    results = {}\n",
        "\n",
        "    for image_file in sorted(image_files):\n",
        "        image_tensor = load_and_preprocess(image_file).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(image_tensor)\n",
        "            predicted_idx = torch.argmax(output, dim=1).item()\n",
        "            predicted_label = index_to_label[predicted_idx]\n",
        "            results[image_file] = predicted_label\n",
        "\n",
        "\n",
        "    for img_name, label in results.items():\n",
        "        print(f\"{img_name}: {label}\")"
      ],
      "metadata": {
        "id": "vVG2JQrxJsLx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}